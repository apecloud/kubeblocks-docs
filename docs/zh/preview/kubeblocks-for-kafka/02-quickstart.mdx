---
description: 使用KubeBlocks部署和管理Kafka副本集集群的完整指南，涵盖安装、配置及运维最佳实践。
keywords:
- Kubernetes
- Kafka
- KubeBlocks
- Helm
- Cluster Management
- QuickStart
sidebar_label: 快速入门
sidebar_position: 2
title: Kafka 快速入门
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Kafka 快速入门

本指南提供了使用 **KubeBlocks Kafka 插件** 部署和管理 Kafka 副本集集群的完整流程，内容包括：
- 系统前提条件与插件安装
- 集群创建与配置
- 操作管理（包括启动/停止流程）
- 连接方法与集群监控

## 前提条件

### 系统要求

开始前请确保您的环境满足以下要求：

- 可正常运行的 Kubernetes 集群（推荐 v1.21+ 版本）
- 已安装并配置好集群访问权限的 `kubectl` v1.21+ 工具
- 已安装 Helm（[安装指南](https://helm.sh/docs/intro/install/)）
- 已安装 KubeBlocks（[安装指南](../user_docs/overview/install-kubeblocks)）

### 验证 Kafka 插件

Kafka 插件默认包含在 KubeBlocks 中。检查其状态：

```bash
helm list -n kb-system | grep kafka
```

<details open>
<summary>示例输出：</summary>

```bash
NAME               NAMESPACE   REVISION    UPDATED                     STATUS      CHART
kb-addon-kafka     kb-system   1           2025-05-21                  deployed    kafka-1.0.0
```
</details>

如果插件未启用，请选择以下安装方式：

<Tabs>

  <TabItem value="helm" label="helm" default>
  ```bash
  # 添加 Helm 仓库
  helm repo add kubeblocks-addons https://apecloud.github.io/helm-charts
  # 中国大陆用户若 GitHub 访问困难或缓慢，可使用以下备用仓库：
  #helm repo add kubeblocks-addons https://jihulab.com/api/v4/projects/150246/packages/helm/stable

  # 更新 Helm 仓库
  helm repo update
  # 搜索可用插件版本
  helm search repo kubeblocks/kafka --versions
  # 安装指定版本（将 <VERSION> 替换为您选择的版本号）
  helm upgrade -i kb-addon-kafka kubeblocks-addons/kafka --version <VERSION> -n kb-system
  ```
  </TabItem>

  <TabItem value="kbcli" label="kbcli">

  ```bash
  # 添加索引（kubeblocks 默认已添加）
  kbcli addon index add kubeblocks https://github.com/apecloud/block-index.git
  # 更新索引
  kbcli addon index update kubeblocks
  # 更新所有索引
  kbcli addon index update --all
  ```

  搜索并安装插件：

  ```bash
  # 搜索插件
  kbcli addon search kafka
  # 安装指定版本插件（将 <VERSION> 替换为您选择的版本号）
  kbcli addon install kafka --version <VERSION>
  ```
  **示例输出：**
  ```bash
  ADDON   VERSION         INDEX
  kafka   0.9.0           kubeblocks
  kafka   0.9.1           kubeblocks
  kafka   1.0.0           kubeblocks
  ```
  启用或禁用插件：

  ```bash
  # 启用插件
  kbcli addon enable kafka
  # 禁用插件
  kbcli addon disable kafka
  ```

  </TabItem>
</Tabs>

:::note
**版本兼容性**

请始终确保 Kafka 插件版本与您的 KubeBlocks 主版本相匹配，以避免兼容性问题。

:::

## 部署 Kafka 集群

使用默认配置部署基础 Kafka 集群：

```bash
kubectl apply -f https://raw.githubusercontent.com/apecloud/kubeblocks-addons/refs/heads/main/examples/kafka/cluster-separated.yaml
```

该操作将创建：
- 一个包含 3 个组件的 Kafka 集群：1 个副本的 Kafka 控制器、1 个副本的 Kafka 代理和 1 个副本的 Kafka 导出器
- 默认资源分配（0.5 CPU，0.5Gi 内存）
- 20Gi 持久化存储

```yaml
apiVersion: apps.kubeblocks.io/v1
kind: Cluster
metadata:
  name: kafka-separated-cluster
  namespace: demo
spec:
  # 指定删除集群时的行为策略
  # 有效选项：[DoNotTerminate, Delete, WipeOut]（KB 0.9 起弃用 `Halt`）
  # - `DoNotTerminate`：阻止删除集群，确保所有资源保持完整
  # - `Delete`：在 `Halt` 策略基础上同时移除 PVC，实现包含持久化数据的彻底清理
  # - `WipeOut`：激进策略，删除包括外部存储中的卷快照和备份在内的所有集群资源，将导致数据完全删除，应谨慎使用（主要用于非生产环境以避免不可逆数据丢失）
  terminationPolicy: Delete
  # 指定创建集群时使用的 ClusterDefinition 名称
  # 注意：请勿修改此字段
  # 值必须为 `kafaka` 才能创建 Kafka 集群
  clusterDef: kafka
  # 指定创建集群时使用的 ClusterTopology 类型
  # - combined：Kafka 控制器（KRaft）与代理合并为单一组件
  # - combined_monitor：合并模式并包含监控组件
  # - separated：KRaft 与代理分离为独立组件
  # - separated_monitor：分离模式并包含监控组件
  # 有效选项：[combined,combined_monitor,separated,separated_monitor]
  topology: separated_monitor
  # 定义组成集群的各个组件的详细配置列表
  componentSpecs:
    - name: kafka-broker
      replicas: 1
      resources:
        limits:
          cpu: "0.5"
          memory: "0.5Gi"
        requests:
          cpu: "0.5"
          memory: "0.5Gi"
      env:
        - name: KB_KAFKA_BROKER_HEAP # 用于设置代理堆内存的 ENV
          value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
        - name: KB_KAFKA_CONTROLLER_HEAP # 用于设置控制器堆内存的 ENV
          value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
          # 是否启用直接 Pod IP 访问模式
          # - 设为 'true' 时，Kafka 客户端将直接通过 Pod IP 连接代理
          # - 设为 'false' 时，客户端将通过 Headless Service 的 FQDN 连接代理
        - name: KB_BROKER_DIRECT_POD_ACCESS
          value: "true"
      volumeClaimTemplates:
        - name: data
          spec:
            storageClassName: ""
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 20Gi
        - name: metadata
          spec:
            storageClassName: ""
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
    - name: kafka-controller
      replicas: 1
      resources:
        limits:
          cpu: "0.5"
          memory: "0.5Gi"
        requests:
          cpu: "0.5"
          memory: "0.5Gi"
      volumeClaimTemplates:
        - name: metadata
          spec:
            storageClassName: ""
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
    - name: kafka-exporter
      replicas: 1
      resources:
        limits:
          cpu: "0.5"
          memory: "1Gi"
        requests:
          cpu: "0.1"
          memory: "0.2Gi"
```

更多 API 字段说明，请参阅 [API 参考文档](../user_docs/references/api-reference/cluster)。

## 验证集群状态

当部署一个包含3个副本的Kafka集群时，可通过以下方式确认部署成功：

1. 集群状态为`Running`
2. 所有Pod均正常运行

可通过以下任一方法检查状态：

<Tabs>
  <TabItem value='kubectl' label='kubectl' default>
```bash
kubectl get cluster kafka-separated-cluster -n demo -w
NAME                      CLUSTER-DEFINITION   TERMINATION-POLICY   STATUS    AGE
kafka-separated-cluster   kafka                Delete               Running   2m48s

kubectl get pods -l app.kubernetes.io/instance=kafka-separated-cluster -n demo
NAME                                         READY   STATUS    RESTARTS   AGE
kafka-separated-cluster-kafka-broker-0       2/2     Running   0          2m33s
kafka-separated-cluster-kafka-controller-0   2/2     Running   0          2m58s
kafka-separated-cluster-kafka-exporter-0     1/1     Running   0          2m9s
```
  </TabItem>

  <TabItem value='kbcli' label='kbcli'>

若已安装`kbcli`，可查看完整的集群信息：

```bash
kbcli cluster describe kafka-separated-cluster -n demo

名称: kafka-separated-cluster  创建时间: 2025年5月19日 16:56 UTC+0800
命名空间   集群定义        拓扑结构            状态      终止策略
demo      kafka          separated_monitor   Running   Delete

访问端点:
组件         内部地址                                                                                 外部地址
kafka-broker  kafka-separated-cluster-kafka-broker-advertised-listener-0.demo.svc.cluster.local:9092   <无>

拓扑结构:
组件            服务版本   实例名称                                     角色     状态     可用区    节点    创建时间
kafka-broker    3.3.2     kafka-separated-cluster-kafka-broker-0       <无>    Running   zone-x   x.y.z   2025年5月19日 16:57 UTC+0800
kafka-controller 3.3.2     kafka-separated-cluster-kafka-controller-0   <无>    Running   zone-x   x.y.z   2025年5月19日 16:56 UTC+0800
kafka-exporter   1.6.0     kafka-separated-cluster-kafka-exporter-0     <无>    Running   zone-x   x.y.z   2025年5月19日 16:57 UTC+0800

资源分配:
组件            实例模板    CPU(请求/限制)    内存(请求/限制)       存储大小       存储类
kafka-controller            500m / 500m     512Mi / 512Mi      元数据:1Gi    <无>
kafka-broker                500m / 500m     512Mi / 512Mi      数据:20Gi
                                                              元数据:1Gi
kafka-exporter              100m / 500m     200GB / 1Gi        <无>         <无>

镜像信息:
组件            组件定义                镜像
kafka-controller  kafka-controller-1.0.0  docker.io/bitnami/kafka:3.3.2-debian-11-r54
                                         docker.io/bitnami/jmx-exporter:0.18.0-debian-11-r20
kafka-broker      kafka-broker-1.0.0      docker.io/bitnami/kafka:3.3.2-debian-11-r54
                                         docker.io/bitnami/jmx-exporter:0.18.0-debian-11-r20
kafka-exporter    kafka-exporter-1.0.0    docker.io/bitnami/kafka-exporter:1.6.0-debian-11-r67

查看集群事件: kbcli cluster list-events -n demo kafka-separated-cluster
```

  </TabItem>
</Tabs>

## 访问 Kafka 集群

**步骤 1. 获取 Kafka 服务的地址**
```bash
kubectl get svc -l app.kubernetes.io/instance=kafka-separated-cluster  -n demo
```

预期输出：
```
NAME                                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
kafka-separated-cluster-kafka-broker-advertised-listener-0   ClusterIP   10.96.131.175   <none>        9092/TCP   5m8s
```
服务名称为 `kafka-separated-cluster-kafka-broker-advertised-listener-0`，位于命名空间 `demo` 中。

**步骤 2. 通过端口号连接 Kafka 集群**

1. 启动客户端 Pod。

  ```bash
  kubectl run kafka-producer --restart='Never' --image docker.io/bitnami/kafka:3.3.2-debian-11-r54 --command -- sleep infinity
  kubectl run kafka-consumer --restart='Never' --image docker.io/bitnami/kafka:3.3.2-debian-11-r54 --command -- sleep infinity
  ```

2. 登录到 kafka-producer。

  ```bash
  kubectl exec -ti kafka-producer -- bash
  ```

3. 创建主题。

  ```bash
  kafka-topics.sh --create --topic quickstart-events --bootstrap-server kafka-separated-cluster-kafka-broker-advertised-listener-0.demo:9092
  ```

4. 创建生产者。

  ```bash
  kafka-console-producer.sh --topic quickstart-events --bootstrap-server kafka-separated-cluster-kafka-broker-advertised-listener-0.demo:9092
  ```

5. 输入："Hello, KubeBlocks" 并按回车键。

6. 开启新的终端会话并登录到 kafka-consumer。

  ```bash
  kubectl exec -ti kafka-consumer -- bash
  ```

7. 创建消费者并指定消费主题，从起始位置消费消息。

  ```bash
  kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server kafka-separated-cluster-kafka-broker-advertised-listener-0.demo:9092
  ```

  此时您将看到输出 'Hello, KubeBlocks'。

## 停止 Kafka 集群

停止集群会暂时暂停运行，同时保留所有数据和配置：

**关键影响：**
- 计算资源（Pod）会被释放
- 持久化存储（PVC）保持完整
- 服务定义得以保留
- 集群配置不会丢失
- 运行成本降低

<Tabs>
  <TabItem value="OpsRequest" label="OpsRequest API" default>
  ```bash
  kubectl apply -f https://raw.githubusercontent.com/apecloud/kubeblocks-addons/refs/heads/main/examples/kafka/stop.yaml
  ```

  ```yaml
  apiVersion: operations.kubeblocks.io/v1alpha1
  kind: OpsRequest
  metadata:
    name: kafka-stop
    namespace: demo
  spec:
    clusterName: kafka-separated-cluster
    type: Stop
  ```
  </TabItem>

  <TabItem value="ClusterAPI" label="Cluster API">
  也可以通过设置 `spec.componentSpecs.stop` 为 true 来停止集群：

  ```bash
  kubectl patch cluster kafka-separated-cluster -n demo --type='json' -p='[
  {
    "op": "add",
    "path": "/spec/componentSpecs/0/stop",
    "value": true
  },
  {
    "op": "add",
    "path": "/spec/componentSpecs/1/stop",
    "value": true
  },
  {
    "op": "add",
    "path": "/spec/componentSpecs/2/stop",
    "value": true
  }
  ]'
  ```
  </TabItem>
</Tabs>

## 启动 Kafka 集群

重启已停止的集群将恢复运行，所有数据和配置保持不变。

**关键影响：**
- 计算资源（Pod）会被重新创建
- 服务将再次可用
- 集群恢复到之前的状态

<Tabs>
  <TabItem value="OpsRequest" label="OpsRequest API" default>

  ```yaml
  apiVersion: operations.kubeblocks.io/v1alpha1
  kind: OpsRequest
  metadata:
    name: kafka-start
    namespace: demo
  spec:
    clusterName: kafka-separated-cluster
    type: Start
  ```
  </TabItem>

  <TabItem value="ClusterAPI" label="Cluster API">
  通过将 `spec.componentSpecs.stop` 设置为 false 来重启集群：

  ```bash
  kubectl patch cluster kafka-separated-cluster -n demo --type='json' -p='[
  {
    "op": "remove",
    "path": "/spec/componentSpecs/0/stop"
  },
  {
    "op": "remove",
    "path": "/spec/componentSpecs/1/stop"
  },
  {
    "op": "remove",
    "path": "/spec/componentSpecs/2/stop"
  }
  ]'
  ```
  </TabItem>
</Tabs>

## 删除 Kafka 集群

请根据数据保留需求谨慎选择删除策略：

| 策略            | 删除的资源          | 数据清除情况       | 适用场景               |
|-----------------|---------------------|--------------------|------------------------|
| DoNotTerminate  | 无                  | 保留所有数据       | 关键生产环境集群       |
| Delete          | 所有Kubernetes资源  | 删除PVC存储卷      | 非关键环境             |
| WipeOut         | 所有资源            | 彻底清除所有数据*  | 仅限测试环境           |

*包含外部存储中的快照和备份数据

**删除前检查清单：**
1. 确认没有应用正在使用该集群
2. 确保已存在必要的备份
3. 验证terminationPolicy设置正确
4. 检查是否存在依赖资源

对于测试环境，可使用以下命令进行完整清理：

```bash
kubectl patch cluster kafka-separated-cluster -p '{"spec":{"terminationPolicy":"WipeOut"}}' --type="merge" -n demo
kubectl delete cluster kafka-separated-cluster -n demo
```