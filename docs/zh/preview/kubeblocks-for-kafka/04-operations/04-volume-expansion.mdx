---
description: 了解如何在KubeBlocks管理的Kafka集群中无停机扩展持久卷声明（PVC）。
keywords:
- KubeBlocks
- Kafka
- Volume Expansion
- Kubernetes
- PVC
sidebar_label: 存储卷扩容
sidebar_position: 4
title: Kafka 集群存储卷扩容
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# 扩展 Kafka 集群存储卷

本指南介绍如何在 **KubeBlocks** 管理的 Kafka 集群中扩展持久卷声明（PVC）。存储卷扩展支持动态增加存储容量，使您的数据库能够随着数据增长无缝扩展。当底层存储类支持此功能时，该操作可在不中断服务的情况下执行。

存储卷扩展允许您在创建持久卷声明（PVC）后增加其容量。该功能在 Kubernetes v1.11 中引入，并在 Kubernetes v1.24 版本正式发布（GA）。

## 前提条件

import Prerequisites from '../_tpl/_prerequisites.mdx'

<Prerequisites />

### 检查存储类是否支持卷扩展

列出所有可用存储类，通过检查 `ALLOWVOLUMEEXPANSION` 字段确认是否支持卷扩展：
```bash
kubectl get storageclass
```

示例输出：
```bash
NAME                PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
gp2                 kubernetes.io/aws-ebs   Delete          WaitForFirstConsumer   false                  4d10h
kb-default-sc       ebs.csi.aws.com         Delete          WaitForFirstConsumer   true                   3d7h
sc-s3-repo-2qsxfh   ru.yandex.s3.csi        Retain          Immediate              false                  3d7h
```
请确保您使用的存储类 `ALLOWVOLUMEEXPANSION` 设置为 true。若为 false，则表示该存储类不支持卷扩展。

## 使用 StorageClass 部署 Kafka 集群

KubeBlocks 采用声明式方式管理 Kafka 集群。以下是一个部署 3 副本 Kafka 集群的配置示例。

应用以下 YAML 配置部署集群：

```yaml
apiVersion: apps.kubeblocks.io/v1
kind: Cluster
metadata:
  name: kafka-separated-cluster
  namespace: demo
spec:
  terminationPolicy: Delete
  clusterDef: kafka
  topology: separated_monitor
  componentSpecs:
    - name: kafka-broker
      replicas: 3
      resources:
        limits:
          cpu: "0.5"
          memory: "0.5Gi"
        requests:
          cpu: "0.5"
          memory: "0.5Gi"
      env:
        - name: KB_KAFKA_BROKER_HEAP
          value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
        - name: KB_KAFKA_CONTROLLER_HEAP
          value: "-XshowSettings:vm -XX:MaxRAMPercentage=100 -Ddepth=64"
        - name: KB_BROKER_DIRECT_POD_ACCESS
          value: "true"
      volumeClaimTemplates:
        - name: data
          spec:
            storageClassName: "<STORAGE_CLASS_NAME>"
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 20Gi
        - name: metadata
          spec:
            storageClassName: ""
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
    - name: kafka-controller
      replicas: 1
      resources:
        limits:
          cpu: "0.5"
          memory: "0.5Gi"
        requests:
          cpu: "0.5"
          memory: "0.5Gi"
      volumeClaimTemplates:
        - name: metadata
          spec:
            storageClassName: "<STORAGE_CLASS_NAME>"
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
    - name: kafka-exporter
      replicas: 1
      resources:
        limits:
          cpu: "0.5"
          memory: "1Gi"
        requests:
          cpu: "0.1"
          memory: "0.2Gi"
```

**关键字段说明**
- `storageClassName`: 指定支持卷扩展的 `StorageClass` 名称。若未设置，将使用标记为 `default` 的 StorageClass。

:::note
**ALLOWVOLUMEEXPANSION**

创建集群时请确保存储类支持卷扩展（检查 `ALLOWVOLUMEEXPANSION`）。

:::


## 验证部署

import VerifyCluster from '../_tpl/_verify-cluster.mdx'

<VerifyCluster />

## 扩展存储卷

:::note
1. 确保存储类支持卷扩展（检查 `ALLOWVOLUMEEXPANSION`）
2. 新容量必须大于当前容量
3. 根据存储提供商不同，卷扩展可能需要额外配置
:::

您可以通过以下两种方式扩展存储卷：
<Tabs>

  <TabItem value="opsRequest" label="OpsRequest API" default>

  方法一：使用 VolumeExpansion OpsRequest

  应用以下 YAML 为 kafka 组件增加存储容量：

  ```yaml
  apiVersion: operations.kubeblocks.io/v1alpha1
  kind: OpsRequest
  metadata:
    name: kafka-separated-cluster-expand-volume-ops
    namespace: demo
  spec:
    clusterName: kafka-separated-cluster
    type: VolumeExpansion
    volumeExpansion:
    - componentName: kafka-broker
      volumeClaimTemplates:
      - name: data
        storage: 30Gi
  ```

  通过以下命令监控扩展进度：

  ```bash
  kubectl describe ops kafka-separated-cluster-expand-volume-ops -n demo
  ```

  预期结果：
  ```bash
  Status:
    Phase:            Succeed
  ```
  完成后，PVC 容量将更新。

  :::note
  如果使用的存储类不支持卷扩展，此 OpsRequest 会快速失败并提示：
  `storageClass: [STORAGE_CLASS_NAME] of volumeClaimTemplate: [VOLUME_NAME]] not support volume expansion in component [COMPONENT_NAME]`
  :::

  </TabItem>

  <TabItem value="ClusterAPI" label="Cluster API">

  方法二：直接更新 Cluster API

  您也可以直接更新 `spec.componentSpecs.volumeClaimTemplates.spec.resources.requests.storage` 字段至目标容量。

  ```yaml
  componentSpecs:
    - name: kafka-broker
      volumeClaimTemplates:
        - name: data
          spec:
            storageClassName: <STORAGE_CLASS_NAME>
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                # 指定新容量，确保大于当前容量
                storage: 30Gi
  ```
  KubeBlocks 将根据新配置自动更新 PVC 容量。
  </TabItem>
</Tabs>

## 验证

检查更新后的集群配置：
```bash
kbcli cluster describe kafka-separated-cluster -n demo
```
预期输出：
```bash
Resources Allocation:
COMPONENT         INSTANCE-TEMPLATE     CPU(REQUEST/LIMIT)   MEMORY(REQUEST/LIMIT)   STORAGE-SIZE   STORAGE-CLASS
kafka-broker                            500m / 500m          512Mi / 512Mi           data:30Gi      <STORAGE_CLASS_NAME>
```
数据 PVC 的存储容量已更新至指定值（本例中为 30Gi）。

确认 PVC 扩容完成：
```bash
kubectl get pvc -l app.kubernetes.io/instance=kafka-separated-cluster,apps.kubeblocks.io/component-name=kafka-broker -n demo
```
预期输出：
```bash
NAME                                              STATUS   VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS
data-kafka-separated-cluster-kafka-broker-0       Bound    pvc-uuid  30Gi       RWO            <STORAGE_CLASS_NAME>
data-kafka-separated-cluster-kafka-broker-1       Bound    pvc-uuid  30Gi       RWO            <STORAGE_CLASS_NAME>
```

## 清理
删除所有创建的资源，包括 Kafka 集群及其命名空间：
```bash
kubectl delete cluster kafka-separated-cluster -n demo
kubectl delete ns demo
```

## 总结

在本指南中您学习了如何：
1. 验证存储类对卷扩展的兼容性
2. 通过以下方式执行卷扩展：
   - 使用 OpsRequest 进行动态更新
   - 通过 Cluster API 进行手动更新
3. 验证更新后的 PVC 容量并确保扩容操作完成

通过存储卷扩展，您可以高效扩展 Kafka 集群的存储容量而无需中断服务，确保数据库能够随着应用需求增长而扩展。