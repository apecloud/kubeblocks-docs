---
title: Observability for Elasticsearch Clusters with the Prometheus Operator
description: Learn how to set up observability for Elasticsearch Clusters in KubeBlocks using the Prometheus Operator. Configure monitoring and visualize metrics with Grafana.
keywords: [KubeBlocks, Elasticsearch, Prometheus, Grafana, Observability, Metrics]
sidebar_position: 2
sidebar_label: Observability for Elasticsearch Clusters
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Elasticsearch Monitoring with Prometheus Operator

This guide demonstrates how to configure comprehensive monitoring for Elasticsearch clusters in KubeBlocks using:

1. Prometheus Operator for metrics collection
2. Built-in Elasticsearch exporter for metrics exposure
3. Grafana for visualization

## Prerequisites

import Prerequisites from '../_tpl/_prerequisites.mdx'

<Prerequisites />

## Install Monitoring Stack

### 1. Install Prometheus Operator
Deploy the kube-prometheus-stack using Helm:

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack \
  -n monitoring \
  --create-namespace
```

### 2. Verify Installation
Check all components are running:
```bash
kubectl get pods -n monitoring
```

Example Output:
```bash
NAME                                                     READY   STATUS    RESTARTS   AGE
alertmanager-prometheus-kube-prometheus-alertmanager-0   2/2     Running   0          114s
prometheus-grafana-75bb7d6986-9zfkx                      3/3     Running   0          2m
prometheus-kube-prometheus-operator-7986c9475-wkvlk      1/1     Running   0          2m
prometheus-kube-state-metrics-645c667b6-2s4qx            1/1     Running   0          2m
prometheus-prometheus-kube-prometheus-prometheus-0       2/2     Running   0          114s
prometheus-prometheus-node-exporter-47kf6                1/1     Running   0          2m1s
prometheus-prometheus-node-exporter-6ntsl                1/1     Running   0          2m1s
prometheus-prometheus-node-exporter-gvtxs                1/1     Running   0          2m1s
prometheus-prometheus-node-exporter-jmxg8                1/1     Running   0          2m1s
```


## Deploy a Elasticsearch Cluster

import CreateCluster from '../_tpl/_create-cluster.mdx'

<CreateCluster />

## Verifying the Deployment

import VerifyCluster from '../_tpl/_verify-cluster.mdx'

<VerifyCluster />

## Configure Metrics Collection

### 1. Verify Exporter Endpoint

```bash
kubectl -n demo exec -it pods/es-multinode-dit-0 -- \
  curl -s http://127.0.0.1:9114/metrics | head -n 50

kubectl -n demo exec -it pods/es-multinode-master-0 -- \
  curl -s http://127.0.0.1:9114/metrics | head -n 50
```

### 2. Create PodMonitor
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: elasticsearch-jmx-pod-monitor
  namespace: demo
  labels:               # match labels in `prometheus.spec.podMonitorSelector`
    release: prometheus
spec:
  jobLabel: app.kubernetes.io/managed-by
  podMetricsEndpoints:
    - path: /metrics
      port: metrics
      scheme: http
  namespaceSelector:
    matchNames:
      - demo
  selector:
    matchLabels:
      app.kubernetes.io/instance: es-multinode
```
**PodMonitor Configuration Guide**

| Parameter | Required | Description |
|-----------|----------|-------------|
| `port` | Yes | Must match exporter port name ('http-metrics') |
| `namespaceSelector` | Yes | Targets namespace where Elasticsearch runs |
| `labels` | Yes | Must match Prometheus's podMonitorSelector |
| `path` | No | Metrics endpoint path (default: /metrics) |
| `interval` | No | Scraping interval (default: 30s) |


## Verify Monitoring Setup

### 1. Check Prometheus Targets
Forward and access Prometheus UI:

```bash
kubectl port-forward svc/prometheus-kube-prometheus-prometheus -n monitoring 9090:9090
```
Open your browser and navigate to:
http://localhost:9090/targets

Check if there is a scrape job corresponding to the PodMonitor (the job name is 'demo/es-multinode-pod-monitor').

Expected State:
- The State of the target should be UP.
- The target's labels should include the ones defined in podTargetLabels (e.g., 'app_kubernetes_io_instance').

### 2. Test Metrics Collection
Verify metrics are being scraped:
```bash
curl -sG "http://localhost:9090/api/v1/query" --data-urlencode 'query=elasticsearch_clusterinfo_up{job="kubeblocks"}' | jq
```

Expected Outputs:
```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "__name__": "elasticsearch_clusterinfo_up",
          "container": "exporter",
          "endpoint": "metrics",
          "instance": "10.244.0.49:9114",
          "job": "kubeblocks",
          "namespace": "demo",
          "pod": "es-multinode-master-2",
          "url": "http://localhost:9200"
        },
        "value": [
          1747666760.443,
          "1"
        ]
      },
... // more lines ommited
```
## Visualize in Grafana

### 1. Access Grafana
Port-forward and login:

```bash
kubectl port-forward svc/prometheus-grafana -n monitoring 3000:80
```
Open your browser and navigate to http://localhost:3000. Use the default credentials to log in:
- Username: 'admin'
- Password: 'prom-operator' (default)

### 2. Import Dashboard
Import the KubeBlocks Elasticsearch dashboard:

1. In Grafana, navigate to "+" â†’ "Import"
2. Import dashboard from [Elasticsearch Dashboard](https://raw.githubusercontent.com/apecloud/kubeblocks-addons/refs/heads/main/addons/elasticsearch/dashboards/elasticsearch.json)

![elasticsearch-monitoring-grafana-dashboard.png](/img/docs/en/elasticsearch-monitoring-grafana-dashboard.png)
Figure 1. Elasticsearch dashboard


## Delete
To delete all the created resources, run the following commands:
```bash
kubectl delete cluster es-multinode -n demo
kubectl delete ns demo
kubectl delete podmonitor es-multinode-pod-monitor -n demo
```

## Summary
In this tutorial, we set up observability for a Elasticsearch cluster in KubeBlocks using the Prometheus Operator.
By configuring a PodMonitor, we enabled Prometheus to scrape metrics from the Elasticsearch exporter.
Finally, we visualized these metrics in Grafana. This setup provides valuable insights for monitoring the health and performance of your Elasticsearch databases.